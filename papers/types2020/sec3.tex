\section{Proof theory and proof certificates}
\label{sec:three}

In this section, we introduce the main ideas from \emph{focused proof
  system}, \emph{foundational proof certificates}, and the
\emph{Coq-Elpi} plugin.

\subsection{Proofs for the Horn fragment}
\label{ssec:focused}

% \todo{Figure now uses Dale kernel-v2 --- needs further abstraction
% and explanation, see appendix} 

A \emph{Horn clause} is a formula of the form $\forall \bar
x_1. A_1\supset \forall \bar x_2. A_2\supset \forall \bar
x_n. A_n\supset A_0$ where $\forall\bar x_i$ denote a list of
universal quantifiers ($i\in\{1,\ldots,n\}$) and $A_0,\ldots,A_n$ are
atomic formulas.  It is well known that the following set of sequent
calculus proof rules are complete for both classical and
intuitionistic logic when one is attempting to prove that a given
atomic formula $A$ is provable from a give set $\Pscr$ of Horn
clauses. 
\[
  \infer[decide]{\Pscr\vdash A}
                {D \in \Pscr\quad \Pscr\Downarrow D\vdash A}
  \qquad
  \infer[init]{\Pscr\Downarrow A\vdash A}{}
\]
\[
  \infer[\forall L]{\Pscr\Downarrow\forall x. D\vdash A}
        {\Pscr\Downarrow D[t/x]\vdash A}
  \qquad
  \infer[\supset L]{\Pscr\Downarrow B\supset D\vdash A}
        {\Pscr\vdash B\qquad \Pscr\Downarrow D\vdash A}
\]
Here, we use two different styles of sequents.  The sequent
$\Pscr\vdash A$ is the usual sequent which we generally use as the end
sequent (the conclusion) of a proof.  The sequent $\Pscr\Downarrow
D\vdash A$ is a \emph{focused} sequent in which the formula $D$ is the
\emph{focus} of the sequent.  The two left introduction rules and the
initial rule can only be applied to the focused formula.  This latter
point is in contrast to Gentzen's sequent calculus where these rules
can involve \emph{any} formula on the left of the $\vdash$.  The fact
that this proof system is complete for both classical and
intuitionistic logic (when restricted to the Horn clause fragment)
follows from rather simple considerations of Horn clauses
\cite{nadathur90jacm} and from the completeness of LJT proofs
\cite{Herbelin94}.  The use of the term \emph{focus} comes from
Andreoli's proof system for linear logic \cite{andreoli92jlc}.

\begin{figure}[t]
\[
\infer{\XXi_1\vdash k\ l : A}
      { \mathrm{Ind}[p] \ (\Gamma_I := \Gamma_C) \in E\quad 
       (\mathit{head} \ A : T)\in \Gamma_I\quad  
       k : D \in \Gamma_C\quad 
       \bc{\XXi_2}{} l D A \quad\unfoldExpert{\XXi_1}{\XXi_2}} 
\]
\vskip -18pt
\[
  \infer{\XXi\vdash  A : s}{{E[] \vdash_{CIC} A : s}}% The order should be s : A, not A : s ?
  %% we are checking nat : Set, for example, so A : s --AM
  \qquad
  \infer{\bc{\XXi}{}{[]} A A}{\initLExpert{\XXi}}
  \qquad
  \infer{\bc{\XXi}{}{(t\ ::\ l)}{\depprod{x}{B}{D}}{A}}
        {\XXi_1\vdash t : B\qquad
         \bc{\XXi_2}{}l {D[t/x]} A\qquad
         \prodE{\XXi}{\XXi_1}{\XXi_2}{t}}
\]
\caption{Specification of the checking of a proof certificate and the
  synthesis of a dependently typed $\lambda$-term.}
\label{fig:augmented}
\end{figure}

\begin{figure}
\lstinputlisting[basicstyle=\ttfamily,language=lprolog,linerange={sigs-end}]{code/dep-kernel.sig}
\lstinputlisting[basicstyle=\ttfamily,language=lprolog,linerange={check-end}]{code/dep-kernel-v2.mod}
\caption{Implementation of a  dependent kernel for Coq terms.}
\label{fig:kernel}
\end{figure}

Figure~\ref{fig:augmented} contains these proof rules and extends them
in the following fours ways so that it more appropriately fits into
the Coq proof system.
\begin{enumerate}
  \item Instead of having separate connectives for $\forall$ and
    $\supset$, we have the dependent product connective $(x:A)D$. 
  \item We have incorporated both \emph{proof certificates}~\cite{chihani17jar} (using the
    schematic variable $\XXi$) along with expert predicates
    (predicates with the $e$ subscript). We explain this in Section~\ref{ssec:cert}.
  \item The inference rules are also annotated by terms structures that
    can be give directly to the Coq kernel for checking.
  \item We have added various premises which are responsible to
    pulling information across the Elpi API with Coq.
\end{enumerate}
The proof system described in Figure~\ref{fig:augmented} (and
implemented in Figure~\ref{fig:kernel}) corresponds to the Calculus
of Inductive Constructions in which all inductive definitions are
limited to the Horn clause.
%
This proof system is inspired by the calculus for proof search in
Pure Type Systems introduced in \cite{LengrandDM06}, based in turn on
ideas stemming from focusing (in particular, the LJT calculus of
Herbelin \cite{Herbelin94}). Similar to that calculus, we have a
term language that includes terms and lists of terms, and two distinct
typing judgments for the two categories.
\begin{metanote}
  This is repeated in 3.2 and isn't too early to talk about code here? -am
\end{metanote}
%
In our case, the \lP goal formula \lsti{(check Xi (go B T))}
corresponds to $\XXi\vdash B \colon T$ and the formula
%
\lsti{(check Xi (bc D B L))} corresponds to $\XXi\Downarrow L\colon
D\vdash B$.
%
This style of  proof terms coincides with the idea behind the \emph{spine
  calculus}~\cite{Cervesato97tr}.  The main novelty of our proof
system here is that proof terms and proof certificates are used
simultaneously in all inference rules.

The proof system is parameterized by Coq's global environment $E$, which
here we take as a set of inductive definitions,
which, following Coq's reference manual, we denote with
$\mathrm{Ind}[p]  (\Gamma_I := \Gamma_C)$.  One  rule delegates
to Coq's type checking the enforcement of the well-sortedness of such types. We
do not have a \emph{local context} since we are only dealing with types
that correspond to Horn clauses, and atomic types are inductively
defined. In fact, we do not have a $\forall$ rule on the right,
although the proof theory would gladly allow it. This means at the
term level that we do not have variables in our grammar of
terms. Terms are always applied to a (possibly empty) list of
arguments.
\begin{metanote}
  Should we call ``unfold'' \emph{decide} (left) and be done with it? AM
\end{metanote}
The \emph{unfold} rule is the equivalent in our simplified setting of
a \emph{decide} rule in an explicitly focused system
\cite{liang09tcs}.  As in the previous proof system for Horn logic,  given an atom,
the rule selects a clause on which to back-chain on: we lookup the
constructors from an \lsti{Inductive} definition from the global
environment, one that matches the atom we wish to backchain on and then
call the latter judgment. The rules for backchaining are standard,
corresponding to the \emph{init} and the (conflation of the) left introduction rules for
$\forall$ and $\supset$.

It may be at first surprising that there are no
introduction rules for propositional connectives, nor equality for
that matter. However, one of the beauty of the Calculus of Inductive
Construction is that they are, in fact,  defined inductively and
therefore the \emph{unfold} rule will handle those; this also
simplifies the syntax of proof-terms.

\subsection{Proof certificate checking}
\label{ssec:cert}
Figure~\ref{fig:kernel} contains the Elpi implementation of the
inference rules in Figure~\ref{fig:augmented}: $\XXi\vdash t \colon A$ corresponds to
\lsti{check $\XXi$ (go A T)} and $\XXi \Downarrow  l \colon D\vdash A$ corresponds to
\lsti{check $\XXi$ (bc D A L)}.
%
The code in that figure mixes both Coq-specific items with
FPC-specific items.  We describe both of these separately.

\subsubsection{Coq-specific code}
Coq terms are accessed through the Coq-Elpi API, and their representation
in \lP takes advantage of the native \lP constructs such as lists and binders.
The following is part of the Coq-Elpi API signature of constants we use:
\begin{lstlisting}[language=lprolog]
kind term   type.                               % reification of Coq terms
kind gref   type.                               % reif. of references to global terms
type global gref -> term.                            % coercion to term
type indt   inductive -> gref.                       % reification of inductive types
type indc   constructor -> gref.                     % reification of their constructors 
type app    list term -> term.                       % reification of nary application
type prod   name -> term -> (term -> term) -> term. % reification of dependent product
\end{lstlisting}
%
Note that \lsti{prod} encodes dependent products taking a name for pretty
printing, a term and a \lP abstraction from terms to terms: namely $(x :
B) D$ is encoded by \lsti{prod ``x'' B (x\ D x)}; when, in the
implementation of the product-left rule, we apply $D$ to the variable
\lsti{Tm}, we get a term that can be used to continue backchaining. This
application is obtained via meta-level substitution, in the style of HOAS. In
this sense, our calculus uses \emph{implicit} substitutions, rather than
explicit ones as in LJT and PTSC's tradition, the more since proof search in
our application is cut-free.
% Syntax: one can think as if something of type \lsti{term -> term} were a
% \lsti{term} with a hole in it for another \lsti{term}.
The unfolding rule makes use of the Coq-Elpi primitives
\lsti{coq.safe-dest-app} in order to obtain the head term of a (possibly
nested) application, and \lsti{coq.env.indt} in order to access the global
environment of inductive definitions and query for information about them.
The \lsti{unfoldE} predicate,  has, among others, the role of selecting which
constructor to introduce for the inductive type. The kernel will successively
obtain the type of the selected constructor, and initiate the backchaining
phase on it.

\subsubsection{FPC-specific code}

Each inference rule in Figure~\ref{fig:augmented} is augmented with an
additional premise involving an \emph{expert predicate} and is
annotated with variables $\Xi$, $\Xi'$, $\Xi_1$, $\Xi_2$ that range
over proof certificates.  These expert predicates are used to extract
information from a certificate.  For example, the premise
$\prodE{\XXi}{\XXi_1}{\XXi_2}{t}$ can be understood as a procedure for
extracting from the certificate $\XXi$ a substitution term $t$ and two
continuation certificates $\XXi_1$ and $\XXi_2$.
%
These notions are taken from the general setting of \emph{foundational
  proof certificates}~\cite{chihani17jar}.
%
%%\todo{MM: Talk about randomized FPC? They mentioned afterwards -am}
In our case here, an FPC is a collection of \lP clauses that provide
the remaining details not supplied in Figures~\ref{fig:augmented}
and~\ref{fig:kernel}: that is, the exact set of constructors for the
type of certificates \lsti{cert} as well as the specification of the expert
predicates listed \emph{ibidem}.
%
The top of Figure~\ref{fig:resources} displays two FPCs,
both of which can be used to describe proofs where we bound
the dimension of  a proof.
%
For example, the first FPC dictates that the query \mbox{\lsti{(check (qheight 5) A)}} is
provable in  the kernel using the clauses in Figures~\ref{fig:kernel}
and~\ref{fig:resources} if and only if the height of that proof is 5
or less.
%
Similarly, the second FPC can be used to bound the total number of instances of
unfoldings in a proof.
%
%In particular, the query \mbox{\lsti{(check (qsize 5 H) B)}}
% \begin{lstlisting}
% sigma H\ (check (qsize 5 H) B)
% \end{lstlisting}
%is provable if and only if the total number of unfoldings of that
%proof is 5 or less.

\begin{figure}[t]
\lstinputlisting[basicstyle=\ttfamily,language=lprolog,linerange={resources-end}]{code/fpcs.sig}
\lstinputlisting[basicstyle=\ttfamily,language=lprolog,linerange={resources-end}]{code/fpcs.mod}
\caption{Sample FPCs}
\label{fig:resources}
\end{figure}

As it has been described in \cite{blanco17cade}, it is also possible
to pair together two different proof certificates, defined by two
different FPC definitions, and do the proof checking in parallel.
This means that we can build an FPC that \emph{restricts} proofs
satisfying two FPCs simultaneously.  In particular, the infix
constructor \lsti{<c>} in Figure~\ref{fig:resources} forms the pair of
two proof certificates and the pairing experts for the certificate
\lsti{Cert1 <c> Cert2} simply request that the corresponding experts
also succeed for both \lsti{Cert1} and \lsti{Cert2} Thus, the query
\lsti{check ((qheight 4) <c> (qsize 10)) A} will succeed if there is a
proof of \lsti{A} that has a height less than or equal to 4 while also
being of size less than or equal to 10.

\subsection{A Prolog-like tactic}

Thanks to the Coq-Elpi interface, in particular to the ``main''
procedure \lsti{solve}, we can package the \lP's code for the checker
as a tactic that can be called as any other tactic in a Coq script.

\begin{lstlisting}[deletekeywords={goal}]
Elpi Tactic dprolog.
Elpi Accumulate lp:{{
  solve [str ''height'', int N] [goal _  Ev G _] _ :-
    coq.say "Goal:" {coq.term->string G},
    check (qheight N) (go G Term),
    Ev = Term,
    coq.say "Proof:" {coq.term->string Ev}.
...
(* Other clauses for different fpc omitted *)
}}.
\end{lstlisting}

The glue code between Coq-Elpi and the implementation of our calculus
is straightforward: the goal is given to us as a quadruple of a (here
inactive) context, an \emph{evar}, a type (goal) and a list of extra
information. In addition, we supply the certificate  when calling the tactic (it simply is an integer and a string to
identify the ``resource'' FPC we will use in this case). We just need
to call \lsti{check} on the goal, together with the
certificate, in order to obtain a reconstructed proof term. We do not
call the reconstruction directly on the evar because Coq-Elpi
ensures that evars manipulated by \lP are well-typed at all times; since
we cannot guarantee that, as we work with partially reconstructed
term, we  get  around this by an explicit unification.

The following
example shows how we can use the above tactic to do FPC-driven logic
programming in Coq and return a Coq proof-term:
\begin{lstlisting}
Inductive insert (x:nat) : list nat -> list nat -> Prop :=
| i_n : is_nat x -> insert x [] [x]
| i_s : forall y: nat, forall ys, x <= y -> insert x (y :: ys) (x :: y :: ys)
| i_c : forall y: nat, forall ys rs, y <= x -> insert x ys rs -> insert x (y :: ys) (x :: rs).
Lemma i1:  exists R, insert 2 [0;1] R.
eexists.
elpi dprolog height 10.
Qed.
Print i1.
ex_intro (fun R : list nat => insert 2 [0; 1] R) [0; 1; 2]
  (i_c 2 0 [1] [1; 2] (i_c 2 1 [] [2] (i_n 2)) : exists R : list nat, insert 2 [0; 1] R
\end{lstlisting}

The \lsti{dprolog} tactic can be seen as a programmable version of
Coq's \lsti{auto}: it currently lacks the latter's capability of
solving goals by \lsti{reflexivity} as well as the modularity of using
\lsti{Hints} as introduction rules; on the bright side, it is not
restricted to depth-first search, since it follows the dictate of the
given FPC, for example iterative-deepening. Furthermore, the FPC can
provide a \emph{trace} that may be more customized than the one
offered by the \lsti{auto}'s hard-wired \lsti{Debug} facility.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:

% LocalWords:  backchaining disjunct LJT dep qheight qsize orE someE
% LocalWords:  Elpi modularity Herbelin bc PTSC's dprolog CIC init lp
% LocalWords:  Andreoli's basicstyle lprolog sigs Coq's sortedness Ev
% LocalWords:  backchain gref indt indc coq dest unfoldings str fpc
% LocalWords:  evar nat forall ys elpi Qed lc args ljf HOAS unfoldE
% LocalWords:  FPCs Prolog evars untyped
