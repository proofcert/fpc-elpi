\RequirePackage[utf8]{inputenc}
\RequirePackage[T1]{fontenc}
\documentclass[a4paper]{easychair}
\usepackage{url,xcolor}
\usepackage{listings}
\usepackage{letltxmacro}
\input{listing-macros}  % Use to get better highlighing of code
\lstset{language=lprolog}
\lstset{language=abella}
\title{On the Proof Theory of Property-Based Testing of Coinductive Specifications, or:\\
 PBT to Infinity and beyond}
\authorrunning{Blanco, Miller and Momigliano}
\titlerunning{PBT to Infinity and
   beyond}
\author{Roberto Blanco\inst{1} \and Dale Miller\inst{2} \and Alberto Momigliano\inst{3}}

\institute{
  INRIA Paris, France
  \and
  INRIA Saclay \& LIX, \'Ecole Polytechnique, France\\
\and
DI, Universit\`a degli Studi di Milano, Italy
}
\begin{document}

\maketitle

Reasoning about infinite computations via coinduction and corecursion
has an ever increasing relevance in formal methods and, in particular,
in the semantics of programming languages, starting
from~\cite{milner91tcs}; see also~\cite{2007-Leroy-Grall} for a
compelling example --- and, of course, coinduction underlies (the
meta-theory of) process calculi. This was acknowledged by researchers
in proof assistants, who promptly provided support for coinduction and
corecursion from the early 90's on, see~\cite{Paulson97,Gim95types}
for the beginning of the story concerning the most popular frameworks.

It also became apparent that tools that search for
refutations/counter-examples of conjectures prior to attempting a
formal proof are invaluable: this is particularly true in PL theory,
where proofs tend to be shallow but may have hundreds of cases.  One
such approach is \emph{property-based testing} (PBT), which employs
automatic test data generation to try and refute executable
specifications.  Pioneered by \emph{QuickCheck} for functional
programming~\cite{claessen00icfp}, it has now spread to most major
proof assistants~\cite{BlanchetteBN11,QChick}.

% DM I revised the following paragraph.  Did I get the sense right?

In general, PBT does not extend well to coinductive specifications
(an exception being Isabelle's \emph{Nitpick},
% \url{https://isabelle.in.tum.de/dist/doc/nitpick.pdf}
which is, however, a counter-model generator).  A particular
challenge, for example, for \emph{QuickChick} is extending it to work
with Coq's notion of coinductive via \emph{guarded} recursion (which
is generally seen to be an unsatisfactory approach to coinduction). We
are not aware of applications of PBT to other form of coinduction, such as \emph{co-patterns}~\cite{AbelPTS13}.

While PBT originated in the functional programming community, we have
given in a previous paper (\cite{Blanco0M19}) a reconstruction of some
of its features (operational semantics, different flavors of
generation, shrinking) in purely proof-theoretic terms employing the
framework of \emph{Foundational Proof Certificates}~\cite{chihani17jar}: the
latter, in its full generality, defines a range of proof structures
used in various theorem provers such as resolution refutations,
Herbrand disjuncts, tableaux, etc.
%
In the context of PBT, the proof theory setup is much simpler.
Consider an attempt to find counter-examples to a conjecture of the
form \(\forall x [(\tau(x)\wedge P(x)) \supset Q(x)]\) where $\tau$ is
a typing predicate and $P$ and $Q$ are two other predicates defined
using Horn clause specifications.
%
By negating this conjecture, we attempt to find a (focused) proof of 
\(\exists x [(\tau(x)\land P(x)) \land \neg Q(x)]\).
%
In the focused proof setting, the \emph{positive phase} (where
test cases are generated) is represented by \(\exists x\) and
\((\tau(x)\land P(x))\). 
%
That phase is followed by the \emph{negative phase} (where conjectured
counter-examples are tested) and is represented by \(\neg Q(x)\).
%
%% turns out to be a search for a proof of \(\exists x [(\tau(x)\land
%%   P(x)) \land \neg Q(x)]\) in a focused sequent calculus for
%% (basically) Horn logic, and pre-condition phase, while proving $Q$ can
%% be relegated to deterministic logic programming-like computation (the
%% \emph{negative} phase), interpreting ``$\neg$'' as
%% Negation-as-failure..
%
FPCs are simple logic programs that guide the search for potential
counter-examples using different generation strategies; they further
capture diverse features such as $\delta$-debugging, fault isolation,
explanation, etc.  Such a range of features can be
programmed as the \emph{clerks and experts} predicates that decorate
the sequent rules used in a FPC proof checking kernel: the kernel
is also able to do a limited amount of proof reconstruction.

As explained in~\cite{Blanco0M19}, the standard PBT setup needs little
more than Horn logic. % specifications.
%
However, when addressing infinite computations, we need richer
specifications.  While coinductive logic programming,
see~\cite{Luke07} and~\cite{BasoldKL19} for a much more principled and
in depth treatment, may at first seem to fit the bill, the need to
model infinite \emph{behavior} rather than infinite objects, that is (ir)rational terms on the
domain of discourse, has lead us to adopt a much stronger logic (and
associated proof theory) with explicit rules for induction and
coinduction.

A natural choice for such a logic is the fixed point logic $\cal
G$~\cite{Gacek2012} and its linear logic cousin $\mu\mathrm{MALL}$~\cite{Baelde12}, which are associated to the \emph{Abella} proof
assistant and the \emph{Bedwyr} model-checker.  In fact, the latter
has already been used for related aims~\cite{HeathM15}.

%and supports reasoning over lambda-tree syntax via the $\nabla$ quantifier. 

To make things more concrete, consider the usual rules for CBV
evaluation in the $\lambda$-calculus with constants, but define it
\emph{coinductively}, following see~\cite{2007-Leroy-Grall}: using Bedwyr's
concrete syntax, this is written as: 
\begin{lstlisting}
Define coinductive coeval: tm -> tm -> prop by
 coeval (con C) (con C);
 coeval (fun R) (fun R);
 coeval (app M N) V := 
   exists R W, coeval M (fun R) /\ coeval N W /\ coeval (R W) V.
\end{lstlisting}
Is evaluation still deterministic?  And if not, can we find terms
\lstinline{E}, \lstinline{V1}, and \lstinline{V2} such that
\mbox{\lstinline{coeval E V1 /\\ coeval E V2 /\\ (V1 = V2 -> false)}}?\footnote{In
  this case equality is purely syntactical, since by construction terms
  will be ground when compared, but the logic implements a richer
  notion~\cite{GacekMN11}.} Indeed we can, since a divergent term such
as $\Omega$ co-evaluates to anything.  In fact, co-evaluation is not
even type sound in its generality. Our PBT approach aims to find such
counter-examples.

It can also be used to separate various notion of
equivalences in lambda and process calculi: for example,
separating applicative and ground similarity in PCFL~\cite{PITobtpe},
or analogous standard results in the $\pi$-calculus.
%
While analogous goals have been achieved for labeled transition systems
and for CCS (using, for example, the \emph{Concurrency Workbench}), it
is a remarkable feature of the proof-theoretic account that is easy to
generalizes PBT from a system without bindings (say, CCS) to a system
with bindings (say, the $\pi$-calculus).
%
Such ease is possible since proof theory accommodates the
\emph{$\lambda$-tree syntax} approach to treating bindings~\cite{miller18jar}: this approach includes the $\nabla$
quantifier~\cite{miller05tocl} that appears in both Abella and Bedwyr.

In our current setup, we attempt to find counter-examples, using
Bedwyr to execute both the generation of test cases (controlled by
using specific FPCs~\cite{Blanco0M19}) and the testing phase.
%
Such an implementation of PBT has the advantages of allowing us to
piggyback on Bedwyr's facilities for efficient proof 
search via tabling for (co)inductive predicates.
%
There are a couple of treatments of the negation in the testing phase.
%
One approach to eliminating negation from intuitionistic specifications
can be based on the techniques in~\cite{Momigliano00}.
%
Another approach identifies the proof theory behind model checking as
the linear logic $\mu$MALL~\cite{HeathM19} and in that setting,
negations can be eliminated by using De Morgan duality (and
disunification).



\bibliographystyle{abbrv}
\bibliography{../colp,../../ppdp19/l}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

%  LocalWords:  Coinductive QuickCheck utf inputenc fontenc Herbrand
%  LocalWords:  corecursion coinductive corecursive QuickChick CBV ir
%  LocalWords:  disjuncts PCFL LTS Harrop PBT Coq's coinductively CCS
%  LocalWords:  intuitionistic FPCs Bedwyr Bedwyr's
