%% IJCAR 2020 CFP: System Descriptions

%% Submissions, not exceeding seven (7) pages excluding bibliography,
%% should describe the implemented tool and its novel features. One
%% author is expected to be able to perform a demonstration on demand to
%% accompany a tool presentation. Papers describing tools that have
%% already been presented in other conferences before will be accepted
%% only if significant and clear enhancements to the tool are reported
%% and implemented. 

%\documentclass[runningheads,11pt]{llncs}
\documentclass{llncs}

\usepackage{proof}
%\usepackage{fullpage}
\usepackage{xspace}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{letltxmacro}
\usepackage{wrapfig}

%\usepackage{hyperref}
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
%\renewcommand\UrlFont{\color{blue}\rmfamily}

\input macros

\begin{document}
\title{\fpccoq: Using ELPI to elaborate external proof evidence into Coq proofs}
%\titlerunning{\fpccoq: Using ELPI in Coq}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here

\author{Roberto Blanco, Matteo Manighetti, and Dale Miller}
\institute{INRIA}
\date{Draft: \today}

\maketitle

\begin{abstract}
The \fpccoq system mixes two systems.
%
The \emph{foundational proof certificate} (FPC) framework is capable
of checking and elaborating a wide range of proof evidence and in
\fpccoq, it is implemented using the logic programming language \lP.
%
The checking a proof certificate in this higher-order logic
programming language can yield a fully detailed, dependently
typed $\lambda$-terms that can be checked by the Coq kernel.
%
We use the recently released Coq-ELPI plugin for Coq in which the ELPI
implementation of \lP can send information to the Coq kernel.
%
As a result of using this plugin, it is possible to provide an
additional procedure (by going around Coq's tactic language) for
building and submitting formal proofs to be checked by the Coq
kernel.
%
Thus, proof certificates come from external provers or from
users can be converted to proofs appropriate for the Coq kernel.
%
When using \fpccoq, as with other Coq tools, 
one only needs to trust the Coq kernel. 
\end{abstract}

% DM Care using proof, proof certificate, proof evidence

\section{Introduction}

The trusted base of Coq is its kernel, which is used to certify that a
given formula has been proved.
%
That kernel checks natural deduction proofs encoded as a certain kind
of dependently typed $\lambda$-term.
%
The rest of the Coq system, especially its tactic language, is
designed to help a human user build proofs-cum-$\lambda$-terms that
can be checked by the kernel.

% RB In standard Coq parlance, the kernel of Coq is the type checker
% that verifies whether the type of the goal (the ``formula'' to be
% proved) can be inhabited by a witnessing term of that type.

Of course, there are many theorem provers for intuitionistic logic for
which a completed proof is not the kind of detailed $\lambda$-term
required by the Coq kernel but is, instead, a trace of some key
aspects of a proof: some proof details might not be captured in such a
trace.  For example:
\begin{enumerate}
\item  Substitution instances of quantifiers might not be
recorded in a proof since such instances can, in principle, be
reconstructed using unification.
\item  Detailed typing information might not need to be stored
within a proof certificate since types can often be reconstructed
during proof checking.
%
% Thus, an untyped $\lambda$-term might provide the key proof-building
% information.  Such terms can be more compact than the fully typed
% term.
%
\item Some simplifications steps might be applied within a proof
  without recording which rewrites were used.  A simple and shallow
  non-deterministic proof-search engine might be expected to
  reconstruct an equivalent simplification.
\end{enumerate}

% RB The connection may not be very useful right now, but usually
% tactics fulfill this role in Coq proof scripts. Pursuing the
% analogy later, FPCs can assume the role of tactical languages with
% clean and proper foundations.

The \emph{foundational proof certificate} (FPC) framework
\cite{chihani17jar} was designed to allow for the formal specification
of such partial proofs.
%
The FPC framework exploits the availability of unification and
backtracking search within the logic programming paradigm to blur the
distinction between proof checking and proof reconstruction. 
%
In particular, an FPC is a logic programming specification of the
\emph{clerk} and \emph{expert} predicates which mediates between the
given (partial) proof evidence and the needs of the logic programming
kernel that both checks and reconstructs all the details needed to
build an internal and formal proof.

The \fpccoq system is built using E. Tassi's Coq-ELPI
\cite{tassi18coqpl,coq-elpi20web}, a new Coq plugin based on the
ELPI~\cite{dunchev15lpar} implementation of \lP
\cite{miller12proghol}.


\section{The FPC framework}

There are at least two significant problems with attempting to use
Gentzen-style sequent calculus proofs for theorem proving and proof
checking: its lack of ``focus'' and determining from where missing
information comes.  We address these two in the next two subsections.

\subsection{Focused proof systems}

\begin{wrapfigure}{r}{45mm}
\vspace{-.9cm}
\[
\infer{\seq{\Gamma}{B_1\lor B_2}}{\seq{\Gamma}{B_i}} 
\quad
\infer{\seq{\Gamma}{\exists x.B}}{\seq{\Gamma}{B[t/x]}} 
\]
\vspace{-.9cm}
\caption{From the LJ calculus}
\label{fig:two unfocused}
\vspace{-.3cm}
\end{wrapfigure}

Consider attempting to prove the LJ sequent
\(\seq{\Gamma}{\exists x\exists y [(p~x~y)\lor ((q~x~y)\lor (r~x~y))]},\)
where $\Gamma$
contains, say, 100 formulas and where two of the introduction
rules are displayed in Fig.~\ref{fig:two unfocused}.
%
The search for a (cut-free) proof
of this sequent confronts the need to choose from among 101
introduction rules.  If the right-side introduction
rule is chosen, the premise of that rule will again present
101 possible introduction rules to consider.
%
Thus, reducing this sequent to, say, $\seq{\Gamma}{(q~t~s)}$ requires
picking one path of choices in a space of $101^4$ choices.

\begin{wrapfigure}{l}{46mm}
\vspace{-.9cm}
\[
\infer{\jRf{\Gamma}{B_1\lor B_2}}{\jRf{\Gamma}{B_i}} 
\quad
\infer{\jRf{\Gamma}{\exists x.B}}{\jRf{\Gamma}{B[t/x]}} 
\]
\vspace{-.8cm}
\caption{Focusing annotations}
\vspace{-.6cm}
\label{fig:two up}
\end{wrapfigure}

Focused proof systems (such as \LJF \cite{liang09tcs}) address this
explosion by organizing rules into two phases in which the sequents
are marked with either $\Downarrow$ or $\Uparrow$.
%
For example, the rules in Fig.~\ref{fig:two unfocused} are written
instead as in Fig.~\ref{fig:two up}.
%
Here, the formula between the $\Downarrow$ and the $\vdash$ is
distinguished: it is the only formula on which an introduction can
take place: as a result, reducing the sequent
\(\jRf{\Gamma}{\exists x\exists y [(p~x~y)\lor ((q~x~y)\lor (r~x~y))]}\)
to $\jRf{\Gamma}{(q~t~s)}$ involves only those choices related to the
formula marked for focus: no interleaving of other choices need to be
considered.

While the $\Downarrow$ phase involves rules that may not be
invertible, the $\Uparrow$ phase involves rules that must be
invertible.  For example, the left rules for $\lor$
and $\exists$ are invertible and their introduction rule is listed as
\[
  \infer{\jUnf{\Gamma}{B_1\veep B_2,\Theta}{\Delta}{E}} %[\veep_l]
        {\jUnf{\Gamma}{B_1,         \Theta}{\Delta}{E}\quad
         \jUnf{\Gamma}{B_2,         \Theta}{\Delta}{E}}
\qquad
  \infer{\jUnf{\Gamma}{\exists x.B, \Theta}{\Delta}{E}}
        {\jUnf{\Gamma}{[y/x]B,      \Theta}{\Delta}{E}} %[\exists_l]
\]
These rules need no external information.  In these
two rules, the zone between $\Uparrow$ and $\vdash$ contains a
\emph{list} of formulas.  When there are no more invertible rules that
can be applied to that first formula, that formula is moved to (i.e.,
stored in) the zone written as $\Gamma$, using the following
\emph{store-left} rule 
\[
  \infer[S_l.]{\jUnf{  \Gamma}{C,\Theta}{\Delta}{E}}
              {\jUnf{C,\Gamma}{  \Theta}{\Delta}{E}}
\]
Finally, when the zone between the $\Uparrow$ and the $\vdash$ is
empty (i.e., all invertible inference rules have been completed),
it is time to select a (possibly non-invertible) introduction rule to
attempt.  For that, we have the two \emph{decide} rules
\[
  \vcenter{\infer[D_l]{\jUnf{\Gamma,N}{\cdot}{\cdot}{E}}{\jLf{\Gamma,N}{N}{E}}}
  \qquad\hbox{and}\qquad
  \vcenter{\infer[D_r.]{\jUnf{\Gamma}{\cdot}{\cdot}{P}}{\jRf{\Gamma}{P}}}
\]
Such focused proof systems can remove a great deal of non-determinism
from proof systems while still being complete \cite{liang09tcs}.


\subsection{Augmenting the proof system with certificates}

The main idea behind the FPC framework \cite{chihani13cade} is that
proof evidence discovered by some theorem prover is packaged up as
some term structure (not necessarily a $\lambda$-term) and 
that term can be given to an independent and trustable proof checker.
%
In order for such a scheme to work, the semantics of the output proof
evidence must be formally defined.
%
The FPC framework provides such formal definitions that are executable
when interpreted using a suitable logic programming
engine~\cite{miller17fac}. 

Consider the following \emph{augmented} versions of inference
rules given in Fig.~\ref{fig:two unfocused}.
\[
\infer{\bXi0 \jRf{\Gamma}{B_1\lor B_2}}
      {\bXi1 \jRf{\Gamma}{B_i}\quad \blue{\orExpert{\Xi_0}{\Xi_1}{i}}}
\qquad
\infer{\bXi0 \jRf{\Gamma}{\exists x.B}}
      {\bXi1 \jRf{\Gamma}{B[t/x]}\quad\blue{\someExpert{\Xi_0}{\Xi_1}{t}}}
\]
In these augmented rules the schema variable $\Xi$ ranges over terms
that denote proof evidence (certificates) and the additional premises
involve \emph{experts} which are predicates that relate the concluding
certificate $\Xi_0$ to a continuation certificate $\Xi_1$ and some
additional information.
%
The expert predicate for the disjunction can provide an indication of
which disjunct to pick and the expert for the existential quantifier
can provide an indication of which instance of the quantifier to use.
%
Presumably, these expert predicates are capable of digging into a
certificate and extracting such information.
%
It is not required, however, for an expert to be able to extract
such information.
%
For example, the disjunction expert might guess both 1 and 2 for $i$
and the proof checker will need to handle such non-determinism during
the checking of certificates.

When formulas are stored (removed from the $\Downarrow$ zone) and
later recalled (using a decide rule), indexes are used to address such
formulas. 
\[
  \infer[S_l]{\bXi0 \jUnfamb{\Gamma}{C,\Theta}{\null}}
             {\bXi1 \jUnfamb{\tupp{l}{C},\Gamma}{\Theta}{\null}\quad
              \blue{\storeClerk{\Xi_0}{\Xi_1}{l}}}
\]
\[
  \infer[D_l]{\bXi0 \jUnf{\Gamma,\tupp{l}{N}}{\cdot}{\cdot}{E}}
             {\bXi1 \jLf{\Gamma,\tupp{l}{N}}{N}{E}\quad
              \blue{\decideExpert{\Xi_0}{\Xi_1}{l}}}
\]
The augmented store-left ($S_l$) rule uses a \emph{clerk} predicate
to determine the index $l$ that is associated to the stored formula
(here, $C$).  The augmented decide-left ($D_l$) rule is given an extra
premise that uses an expert predicate: that premise can be used to
compute the index of the formula that is to be selected for focus.
%
The indexing mechanism does not need to give unique indexes to
different formulas: thus, the decide rule may be seen as
non-deterministically selecting a formula from storage.
%
With FPCs, indexes have been identified with
structures as diverse as formula occurrences and de Bruijn numerals
\cite{chihani17jar}.


\subsection{Examples of FPC specifications}

A simple proof certificate is essentially a natural number that denotes
the maximum number of decide rules that can occur along a path from
the root sequent.
%
Thus, checking that such a number is a valid proof certificate for a
formula essentially causes the proof check to enumerate all proofs
that have such a bounded number of decide rules.
%
The definition of some key experts and clerks for the definition of
this certificate are produced below: here, \lsti{s} is the non-zero
constructor for natural numbers and \lsti{dd} maps natural numbers
into the type of certificate terms (the syntax \lsti{x\} denotes
$\lambda x$ in \lP---here, this binding is vacuous).
{\small
\begin{lstlisting}
some_je    (dd D) (dd D) Term.       % _j refers to LJ 
or_jc      (dd D) (dd D) (dd D).     % e denotes experts
or_je      (dd D) (dd D) I.          % c denotes clerks
storeL_jc  (dd D) (x\ dd D) (x\ indx).
decideL_je (dd (s D)) (dd D) indx.
\end{lstlisting}
}
Here, we note that all stored formulas get the same index \lsti{indx}
and that the \lsti{decideL_je} expert always provides that index as
the source of the formulas to select.  Note also that both the expert
\lsti{some_je} allows any term to instantiate the existential
quantifier and that \lsti{or_je} allows both disjunctions to be
selected.
%
Many other (more sophisticated) FPCs appear in 
\cite{blanco15wof,blanco17lfmtp,chihani15tableaux,chihani16lfsa,chihani17jar,heath15pxtp}.

The \emph{pairing} FPC was presented in \cite{blanco17cade} and it was
used to show that two FPCs can be checked to hold simultaneously for a
given sequent.
%
Since the logic programming setting allows us to see proof checking
and proof reconstruction as two aspects of the \emph{same} execution,
it is possible to use pairing to check one certificate following one
FPC definition and to reconstruct a second certificate following a
different FPC definition.
%
In \cite{blanco17cade}, that pairing FPC was used to show how a given
proof certificate can be \emph{elaborated} (converted to a format with
more details) or \emph{distilled} (converted to a format with fewer
details).

\section{\fpccoq: making Coq interact with proof certificates}

\subsection{The FPC for Coq kernel terms}

%\lstinputlisting[linerange={7-10}]{termrep/repterm.sig}

%  - Illustrate both interactive and batch uses.
The first step towards making the framework of Foundational Proof
Certificates and the Coq proof assistant cooperate is the definition of a
proof certificate that explains how to consume Coq terms as proof evidence
for a formula. We can restate the problem with the terminology of the
\emph{formulas-as-types} tradition Coq sits in: here, for a given term, being
a proof of some formula amounts to having a certain type; the problem of
devising a definiton of a proof certificate that can consume Coq terms is
then equivalent to the problem of programming a type checker in terms of the
clerks and experts.

Coq lambda terms are directly isomorphic to proofs in a flavour of natural
deduction. In contrast, our approach is based on the sequent calculus: this
requires our approach to type checking to be slightly finer, and akin to
other analysis of the interpretations of focusing in the lambda calculus
\cite{brocknannestad15mfps} %% TODO: At which moment should I mention that we don't do inductive types?
Moreover, we should stress once again that we are only
targeting the first order fragment of the Calculus of Constructions, without
inductively defined types. The usual presentation of connectives as inductive
types is directly translated to the usual connectives of intuitionistic first
order logic, that are the only ones to be known to the FPC checker.

Let's start looking into the definition of the clerks and experts for type
checking by examining the handling of the implication. An implication
occurring in the type must correspond to a lambda abstraction occurring in
the term, and is handled by the \lsti{arr_jc} clerk that will simply remove
the binder, and return a term with an open variable.

{\small
\begin{lstlisting}
arr_jc (coqcert (fun _name _type F)) (coqabs F).
\end{lstlisting} }

Note that we need two certificate constructors: \lsti{coqcert} indicates that
the certificate being handled is a closed term; \lsti{coqabs} indicates that
it is a term with an open variable. The open variable is then bound to the
proof tree by the \lsti{storeL_jc} that takes an open term and returns to the
kernel an open certificate and an open index: the kernel will then bind both the
certificate and the term to the same variable.

{\small
\begin{lstlisting}
storeL_jc (coqabs T) (x\ coqcert (T x)) (x\ idxoftm x).
\end{lstlisting}
}

A logical account of the process is the following:

\[
  \infer[I_r]{\Xi_0 : (fun\; x : A \Rightarrow t), \jUnfG{\null}{A\to B }}
             {\infer[S_l]{\Xi_1 : (t), \jUnfG{A}{B}\quad
              \blue{\arrClerk{\Xi_0}{\Xi_1}}}{
                \Xi_2 : (t x), \jUnf{\Gamma, x : A}{\null}{B}{\null} \quad \blue{\storeClerk{\Xi_1}{\Xi_2(x)}{x}}
              }
             }
\]
The certificate now contains the variable $x$ that is bound in the kernel, and allows
a reference to the formula $A$. The immediate store of the formula happens only if it is
atomic; otherwise, a phase similar to a pattern matching phase happens.
For example, if the formula to the left of the implication sign is of the form
$A \lor B$, then the \lsti{or_jc} clerk is used. Its specification is
{\small
\begin{lstlisting}
or_jc (coqabs (x\ app {{or_ind F1 F2 lp:x}})) (coqabs T1) (coqabs T1) :-
  F1 = fun _ _ T1,
  F2 = fun _ _ T2.
\end{lstlisting}
}

Thus, the term with an open variable that would accept a disjunction type is
immediately decomposed into two terms with open variables for each of the
disjuncts. The initial proof term must contain a disjunction elimination
applied to the open variable: note that thanks to Coq-Elpi we can use a quoting operator and include
a term in the syntax of Coq inside a \lP clause. The new proof terms are just
the cases for the two disjuncts that we extract.

% % Not used at the moment: arr_je
% In the case the formula to the left of an
% implication is another implication, this phase is handled by the
% \lsti{arr_je} expert:

% {\small
% \begin{lstlisting}
% arr_je (coqabs (x\ app [x,T])) (coqcert T) (coqabs (x\ x)).
% \end{lstlisting} }

% This specifies that if the free variable of an open term (of some type
% $A$) has the type of an implication $B \to C$, then the term must be of the
% form $xt$, and one can use the implication left rule and continue checking
% that $x$ is an open term of type $A$ and $t$ is a closed term of type 

\subsection{Tactics for proof certificates}
As we mentioned at the end of the previous section and at the beginning of 
this one, thanks to the purely declarative spirit of the implementation
of the checkers for FPCs the difference between proof checking and proof
reconstruction is blurred; the \emph{pairing} FPC helps in this direction
and allows for a declarative way to extract synthesised proofs in a format
starting from proofs in another format. Employing it together with the FPC
specification we have just given for Coq proof terms, we obtain a system
that can build proofs that can be checked by the Coq kernel starting from
external proofs given in any format for which an FPC definition is available.

The Elpi extension for Coq provides the facilities for building tactics
written in \lP. The code for the kernel of our proof checker, as well
as the FPC definitions that have already been produced could thus be
used right away to build our tactic. Some preprocessing code transforms Coq
types into first order formulas that our kernel can recognize,
handles the external proof evidence and pairs it (in the sense of the
\emph{pairing} FPC) with an empty proof term,
so that a run of the proof checker reconstructs it.

Let's consider a definition of a Proof Certificate, such as the one described above
\small{
  \begin{lstlisting}
ljf_entry ((dd N) <c> (coqcert Term)) Form.
  \end{lstlisting}
}
Where \lsti{<c>} denotes the pairing between the two certificate formats.
We then have a tactic that will have a natural as parameter, and that we can call in 
the usual way in a Coq proof:
\small{
  \begin{lstlisting}
Lemma example1 : forall A B: Prop, (A -> B) -> A -> B.
Proof.
elpi dd_fpc 2.
Qed.
  \end{lstlisting}
}

\subsection{Handling dependent types in the kernel}
The proof checking kernel in the Foundational Proof Certificates program is
meant to be a small trusted base. For this reason, given its origins in the
theory of focused sequent calculus, it only implements a minimalistic
sequent calculus in a purely decladative fashion.
In this context, however, we could also decide to keep Coq kernel as a trusted checker,
and to allow for extensions in the FPC checker kernel.

With this in mind, we developed a second solution where we extend the kernel 
of our proof checker with dependent types and reconstruction of Coq proof terms, 
in the style of \cite{lengrand10lmcs}.

This allows for a much more concise implementation, where there is no translation 
needed from Coq formulas to intuitionistic formulas since the kernel directly operates
with dependent types. The usual definitions of proof certificates remain directly usable
also in this context.

The code for both implementations is available at \url{https://gitlab.inria.fr/rblancom/fpc-elpi}

\section{Related work}

This paper can be seen as part of the larger effort to use \lP within
a type theory setting \cite{coen19mscs}, in general, and within Coq
\cite{tassi19itp}, in particular.

This particular version of \fpccoq only works on proving theorems in
first-order intuitionistic logic.
%
Given that the \lP proof checker based on \LJF can also serve as a
proof checker for \LKF (a focused version of classical sequent
calculus), \fpccoq can be used to prove double negation translations 
of a formula for which there is a proof certificate in classical
logic \cite{chihani17jar}.

The goals of the Dedukti framework overlap some of the goals of the
\fpccoq system. 
%
In particular, a great deal of work has gone into providing back-ends
to numerous proof assistant so that their proofs can be output in the
Dedukti format \cite{assaf16unp,assaf16types,cauderlier16phd}. 
%
The Dedukti interpreter can then provide an independent certification
of the correctness of the proof.
%
Although \fpccoq targets the construction of proofs for the Coq kernel
only, it should be straightforward to use the same setup described
here to build Dedukti proofs as well.


% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
\bibliographystyle{splncs04}
\bibliography{../../references/master}
%\bibliography{export}  % Use the Makefile to great this smaller bib file
\end{document}

%%  LocalWords:  Matteo Coq's Tassi's trustable basicstyle keepspaces
%%  LocalWords:  storeL jc indx decideL je storeR
